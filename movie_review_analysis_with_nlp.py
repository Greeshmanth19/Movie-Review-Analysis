# -*- coding: utf-8 -*-
"""Movie review analysis  with NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YTXsKXxBe4u677sZXgetEENdJkxl-654

# Natural Language Processing (NLP)

# Bag Of Words model for Movie Review Analysis

### importing libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

"""### importing dataset"""

data = pd.read_csv("/content/labeledTrainData.tsv", delimiter="\t", quoting=3)

data.head()

data.drop("id", axis = 1, inplace = True)

print(len(data.index))

"""### Cleaning Text"""

import re
import nltk # natural language tool kit
nltk.download("stopwords")  # downloads the stopwords like the, an, a, etc which doest help in predicting the sentiments of the sentence
from nltk.corpus import stopwords # importing the stopwords that have been downloaded
from nltk.stem.porter import PorterStemmer
# porterstemmer is used for steming. steming means will help in reducing the complexcity by reducing and conerting the words into present fromate .
# It simplify each word with the root of that word like loved -> love and etc ...

corpus = []
neg_words = ("not", "haven't", "won't", "mightn't", "doesn't", "needn't", "wouldn't", "hadn't", "don't", "aren't", "wasn't", "no", "couldn't", "weren't", "didn't", "shan't", "mustn't")
for i in range(0, 25000):
  review = re.sub("^a-zA-Z", " ", data["review"][i])  # The sub() is used to replace any char with any given char .
                                                      # removes all type of charactors that are not lie betweeen A to Z and a to z .
  review = review.lower()  # conver the text into lower case
  review = review.split()  # split the sentance into words and store it as a list
  ps = PorterStemmer()
  all_stopwords = stopwords.words('english')
  for j in neg_words:
    all_stopwords.remove(j)
  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]  # removing stopwords from the  text and perfromming steming on the each word .
  review = " ".join(review)   # converting the list into a string .
  corpus.append(review)

print(len(corpus))

"""### Building Bag Of Words model"""

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features=1700)
X = cv.fit_transform(corpus).toarray()
y = data.iloc[:,0:1].values

print(len(X[0]))

print(X[:3])

print(y[:5])

"""### Spliting the train and testing data"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

"""### Training Logistic Regression"""

from sklearn.linear_model import LogisticRegression
LR = LogisticRegression()
LR.fit(X_train, y_train)
LR_y_p = LR.predict(X_test)

result = []
for i in range(0, len(y_test)):
  result.append([int(y_test[i]), LR_y_p[i]])
final_result = pd.DataFrame(result)
final_result.columns = ["Actual value", "Predicted value"]

final_result

"""### Evaluating the model using confusion matrix"""

from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, LR_y_p)
acc = accuracy_score(y_test, LR_y_p)

disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=LR.classes_)
disp.plot()
plt.show()

print("Accuracy : ", acc*100, "%")

from sklearn.metrics import classification_report
cr = classification_report(y_test, LR_y_p)
print(cr)